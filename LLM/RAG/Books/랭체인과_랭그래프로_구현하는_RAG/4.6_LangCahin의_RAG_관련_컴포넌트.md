LangChain의 RAG 관련 컴포넌트

# RAG(Retrieval-Augumented Generation)

질문과 관련된 문서를 context에 포함시킴으로써 LLM이 본래 알지 못하는 내용에 대해서도 답변을 얻을 수 있다. 다만, LLM에는 토큰 수의 최댓값 제한이 있어 모든 데이터를 context에 넣을 수는 없다.  
따라서 입력을 바탕으로 문서를 검색하고, 검색 결과를 context에 포함하여 LLM에게 답변하게 하는 기법이 있고 이를 RAG(Retrieval-Augumented Generation)이라고 한다.  
RAG의 전형적인 구성은 벡터 데이터베이스를 사용해 문서를 벡터화하여 저장해 두고, 입력 텍스트와 벡터가 가까운 문서를 검색하여 context에 포함시키는 것이다. 문서의 벡터화에는 OpenAI의 Embeddings API 등을 사용

# LangChain의 RAG 관련 컴포넌트 개요

- Document loader: 데이터 소스에서 문서를 읽어 들임
- Document transformer: 문서에 어떤 변환을 가함
- Embedding model: 문서를 벡터화함
- Vector store: 벡터화한 문서의 저장소
- Retriever: 입력 텍스트와 관련 있는 문서를 검색함

# Document loader

데이터 읽기에 사용 하는 것이 'Document loader'이다. 여기서는 GitHub에 공개된 LangChain 공식 문서를 읽어들이겠다.  

우선 langchain-community와 GitPython 패키지 설치

```bash
pip install langchain-community==0.3.0 GitPython==3.1.43
```

Document loader의 한 종류인 GitLoader를 사용해 LangChain 저장소에서 .mdx라는 확장자 파일을 읽어들인다.

```python
from langchain_community.document_loaders import GitLoader

def file_filter(file_path: str) -> bool:
    return file_path.endswith(".mdx")

loader = GitLoader(
    clone_url="https://github.com/langchain-ai/langchain",
    repo_path="./langchain",
    branch="master",
    file_filter=file_filter,
)

raw_docs = loader.load()
print(len(raw_docs))
# 277
```

---

# Document transformer

읽어 들인 문서에 변환을 가하는 것이 'Document transformer'이다.  
예를 들어 문서의 길이를 청크로 분할하는 경우 LangChain에서 문서를 청크화하는 기능군을 'Text splitter'라고 부르며, langchain-text-splitters 라는 패키지로 분리돼 있다. 

```bash
pip install langchain-text-splitters==0.3.0
```

```python
from langchain_text_splitters import CharacterTextSplitter

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)

docs = text_splitter.split_documents(raw_docs)
print(len(docs))
# 925
```

원래 277개였던 문서가 925개로 분할되었다.

또한 문서를 청크로 분할하는 것 외에도 몇 가지 변환 처리가 지원된다.

|Document transformer|개요|
|---|---|
|Html2TextTransformer|HTML을 일반 텍스트로 변환|
|OpenAIMetadataTagger|메타데이터 추출|
|GoogleTranslateTransformer|문서 번역|
|DoctranQAtransformer|사용자 질문과 관련성을 높이기 위해 문서에서 Q&A 생성|

# Embedding model

문서의 변환 처리를 마치면 텍스트를 벡터화 한다. 이 예시에서는 OpenAI의 Embeddings API를 사용해 text-embedding-3-small 모델로 텍스트를 벡터화한다. LangChain에는 OpenAI의 Embeddings API를 래핑한 OpenAIEmbeddings라는 클래스가 있다. OpenAIEmbeddings 처럼 텍스트를 벡터화에 사용할 수 있는 것이 'Embedding model'이다.

```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
```

OpenAIEmbeddings를 사용해 텍스트를 벡터화해 보겠다.

```python
query = "AWS의 S3에서 데이터를 읽어 들이기 위한 Document loader가 있나요?"

vector = embeddings.embed_query(query)
print(len(vector))
# 1536
print(vector)
# [0.0056423, 0.0028112, ... ]
```

# Vector store

이 장에서는 'Chroma'라는 로컬 Vector store를 사용하겠다.  

```bash
pip install langchain-chroma==0.1.4
```

```python
from langchain_chroma import Chroma

db = Chroma.from_documents(docs, embeddings)
```

참고로 LangChain에서는 Chroma 외에도 Faiss, Elasticsearch, Redis 등 Vector store로 사용할 수 있는 많은 통합이 제공된다.  
Vector store에 대해서는 사용자 입력과 관련된 문서를 가져오는 조작을 수행한다. LangChain에서 텍스트와 관련된 문서를 가져오는 인터페이스를 'Retriever'라고 한다.  

Vector store의 인스턴스에서 Retriever를 생성한다.

```python
retriever = db.as_retriever()
```

Retriever를 사용해 시험삼아 질문과 가까운, 즉 관렷ㅇ이 높은 문서를 검색해보겠다.

```python
query = "AWS의 S3에서 데이터를 읽어 들이기 위한 Document loader가 있나요?"

context_docs = retriever.invoke(query)
print(f"len = {len(context_docs)}")
# len = 4

first_doc = context_docs[0]
print(f"metadata = {first_doc.metadata}')
print(first_doc.page_content)
```

Retriever 내부에서는 제공된 텍스트를 벡터화해 Vector store에 저장된 문서 중에서 벡터 거리가 가까운 것을 찾는다.

# LCEL을 사용한 RAG Chain 구현

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

prompt = ChatPromptTemplate.from_template('''\
다음 문맥만을 바탕으로 질문에 답변해 주세요.

문맥: """
{context}
"""

질문: {question}
''')

model = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

# 이어서 LCEL로 RAG Chain을 구현하고 실행한다
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | model
    | StrOutputParser()
)

output = chain.invoke(query)
print(output)
# 네, AWS S3에서 데이터를 읽어 들이기 위한 ...
```

