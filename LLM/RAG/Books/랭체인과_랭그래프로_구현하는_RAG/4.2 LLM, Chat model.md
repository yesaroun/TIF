# LLM
LLM은 하나의 텍스트 입력에 대해 하나의 텍스트 출력을 반환하는, 채팅 형식이 아닌 언어 모델을 다루는 컴포넌트이다.

```python
from langchain_openai import OpenAI

model = OpenAI(model="gpt-3.5-turbo-instruct", temperature=0)
output = model.invoke("안녕하세요. ")
print(output)
```

이 코드에서 모델로 gpt-3.5-turbo-instruct를 설정하고, temperature로 0을 설정했다. temperature는 값이 클 수록 출력이 무작위해지는 매개변수이다.

여기서는 어디까지나 하나의 텍스트 입력에 대해 하나의 텍스트 출력을 반화하는, 채팅 형식이 아닌 언어 모델의 예시로 사용한다.

# Chat model

OpenAI의 Chat Completions API는 텍스트를 입력하는 것이 아니라, 채팅 형식의 대화를 입력하여 응답을 얻는 형태로 돼 있다. 이러한 채팅 형식의 언어 모델을 LangChain에서 다루기 위한 컴포넌트가 'Chat model'이다.  

# 스트리밍

LangChain에서 기본적인 사용버으로 스트리밍도 지원

# LLM과 Chat model의 상속 관계

```text
             ┌───────────────┐
             │   Runnable    │
             └───────▲───────┘
                     │ 상속 ※1
      ┌──────────────┴──────────────┐
      │      BaseLanguageModel      │
      └───────▲───────────▲─────────┘
              │ 상속       │ 상속
 ┌────────────┴───┐   ┌───┴────────────┐
 │    BaseLLM     │   │  BaseChatModel │
 └───────▲──▲─────┘   └────▲──────▲────┘
         │  │ 상속         │ 상속  │
         │  │             │       │
┌────────┘  └───────┐  ┌──┘       └────────────────────────┐
│ OpenAI    기타 LLM │  │  ChatOpenAI      기타 Chat model   │
└───────────────────┘  └───────────────────────────────────┘
```

Runnable을 상속한 BaseLanguageModel이라는 클라스가 있다. BaseLanguageModel은 LangcChain에서 언어 모델을 다루는 데 쓰이는 가장 상위 클래스이다. 그리고 BaseLanguageModel을 상속한 BaseLLM과 BaseChatModel이 존재한다.

OpenAI 클래스나 기타 LLM 클래스는 BaseLLM을 상속하며, ChatOpenAI 클래스나 기타 Chat model 클래스는 BaseChatModel을 상속한다.

