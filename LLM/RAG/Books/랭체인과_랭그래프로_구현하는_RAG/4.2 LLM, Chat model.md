# LLM
LLM은 하나의 텍스트 입력에 대해 하나의 텍스트 출력을 반환하는, 채팅 형식이 아닌 언어 모델을 다루는 컴포넌트이다.

```python
from langchain_openai import OpenAI

model = OpenAI(model="gpt-3.5-turbo-instruct", temperature=0)
output = model.invoke("안녕하세요. ")
print(output)
```

이 코드에서 모델로 gpt-3.5-turbo-instruct를 설정하고, temperature로 0을 설정했다. temperature는 값이 클 수록 출력이 무작위해지는 매개변수이다.

여기서는 어디까지나 하나의 텍스트 입력에 대해 하나의 텍스트 출력을 반화하는, 채팅 형식이 아닌 언어 모델의 예시로 사용한다.

# Chat model
