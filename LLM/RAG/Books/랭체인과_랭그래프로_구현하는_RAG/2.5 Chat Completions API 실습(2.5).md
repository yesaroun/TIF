p24~

OpenAI 공식 파이썬 라이브러리 사용한다.

```bash
pip install openai==1.40.6
```

# Chat Completions API 호출

```python
from openai import OpenAI

client = OpenAI()

response = client.chat.completions.create(
	model="gpt-4o-mini",
	messages=[
		{"role": "system", "content": "You are a helpful assistant."},
		{"role": "user", "content": "안녕하세요! 저는 존이라고 합니다!"},
	],
)
print(response.to_json(indent=2))
```

응답
```json
{
	"id": "chatcmpl-AedfdDSd",
	"choices": [
		{
			"finish_reason": "stop",
			"index": 0,
			"logprobs": null,
			"message": {
				"content": "안녕하세요, 존님! 만나서 반갑습니다.",
				"refusal": null,
				"role": "assistant"
			}
		}
	],
	"created": 19912,
	"model": "gpt-4o-mini-2024-03-12",
	"object": "chat.completion",
	"system_fingerprint": "fp_34232",
	"usage": {
		"completion_tokens": 27,
		"prompt_tokens": 25,
		"total_tokens": 52
	}
}
```

# 대화 이력을 고려한 응답 얻기

Chat completions API는 스테이트를 저장하지 않고, 과거 요청 대화 기록을 고려한는 기능은 없다. 과거 요청을 고려하도록 하려면 과거 대화를 요청에 포함해야 한다.
사람의 입력을 "role": "user", AI의 입력을 "role": "assistant"

# 스트리밍으로 응답 얻기

스트리밍으로 응답을 얻을 때는 요청에 stream=True 라는 파라미터 추가

```python
response = client.chat.completions.create(
	model='gpt-4o-mini',
	messages=[
		{'role': "system", "content": "You are a helpfule assistant."},
		{'role': 'user', 'content': '안녕하세요 저는 존입니다.'},
	],
	stream=True,
)

for chunk in response:
	content = chunk.choices[0].deltal.content
	if content is not None:
		print(content, end='', flush=True)
```

# 기본 파라미터

model, messages, stream 이외에도 다음과 같은 파라미터 추가 가능

| 파라미터명       | 개요                                     | 기본값   |
| ----------- | -------------------------------------- | ----- |
| temperature | 0~2 사이의 값으로 클수록 출력이 무작위해지고, 작을수록 결정적이됨 | 1     |
| n           | 생성되는 텍스트 후보의 수                         | 1     |
| stop        | 등장하는 시점에 생성을 중지하는 문자열(또는 그 배열)         | null  |
| max_tokens  | 생성할 최대 토큰 수                            | null  |
| logprobs    | 출력 토큰의 로그 확률을 반환할지 여주                  | false |

https://platform.openai.com/docs/api-reference/chat/create
참조

# JSON 모드

LLM 애플리케이션 통합해 사용할때 JSON 형식 출력을 얻고 싶은 경우가 많다.
JSON 모드를 사용하려면 프롬프트에 "JSON" 문자열을 포함시기고 response_format 파라미터에 `{'type': 'json_object'}` 값 지정

```python
from openai import OpenAI

client = OpenAI()

response = client.chat.completions.create(
	model='gpt-4o-mini',
	messages=[
		{
			'role': 'system',
			'content': '인물 목록을 다음 json형식으로 출력해 주세요.\n{"people": ["aaa", "bbb"]}',
		},
		{
			'role': 'user',
			'content': '옛날 옛적에 할아버지와 할머니가 살고 있었습니다',
		},
	],
	response_format={'type': 'json_object'},
)
print(response.choices[0].message.content)
# {'people': ['할머니', '할아버지']}
```

# Vision(이미지 입력)

gpt-4o, gpt-4o mini 는 이미지 입력도 지원.
Chat Completions API에 대한 요청에 이미지 URL이나 Base64로 인코딩된 이미지를 포함시키면 이미지 내용을 고려한 응답을 얻을 수 있다.

```python
from openai import OpenAI

client = OpenAI()

image_url = "https://raw.githubusercontent.com/ychoi-kr/langchain-book/main/cover.jpg"

response = client.chat.completions.create(
	model='gpt-4o-mini',
	messages=[
		{
			'role': 'user',
			'content': [
				{'type': 'text', 'text': '이미지를 설명해 주세요.'},
				{'type': 'image_url', 'image_url': {'url': image_url}},
			],
		}
	],
)

print(response.choices[0].message.content)
```
