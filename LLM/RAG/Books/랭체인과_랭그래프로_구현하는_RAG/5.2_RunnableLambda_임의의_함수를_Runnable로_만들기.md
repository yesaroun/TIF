RunnableLambda-임의의 함수를 Runnable로 만들기(5.2)

LLM 애플리케이션에서는 LLM의 응답에 대해 규칙 기반으로 추가 처리를 하거나 어떤 변환을 적용하고 싶은 경우가 많다. RunnableLambda를 사용하면 LCEL의 Chain에 임의의 처리(함수)를 연결할 수 있다.

예를 들어 LLM이 생성한 텍스트에 대해 소문자를 대문자로 변환하는 처리를 연결하는 Chain을 구현해보겠다.

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "Your are a helpful assistant."),
        ("human", "{input}"),
    ]
)

model = ChatOpenAI(model="gpt-4o-mini", temperature=0)

output_parser = StrOutputParser()
```

소문자를 대문자로 변환하는 함수를 구현하고 이 들을 Chain으로 연결해 실행한다.

```python
from langchain_core.runnables import RunnableLambda

def upper(text: str) -> str:
    return text.upper()

chain = prompt | model | output_parser | RunnableLambda(upper)

ai_message = chain.invoke({"input": "Hello!"})
print(ai_message)
# HELLO! HOW CAN I ASSIST YOU TODAY?
```

대문자로 변환되었다. RunnableLambda를 사용하면 임이의 함수를 Runnable로 변환할 수 있다. LLM 호출과 사용자 정의 처리를 연결하고 싶은 경우가 많으므로 RunnableLambda를 자주 사용하게 될 것이다.

# chain 데코레이터를 사용한 RunnableLambda 구현

RunnableLambda를 생성하기 위해 chain 데코레이터(@chain)를 사용할 수도 있다.

```python
from langchain_core.runnables import chain

@chain
def upper(text: str) -> str:
    return text.upper()

chain = prompt | model | output_parser | upper

ai_message = chain.invoke({"input": "Hello!"})
print(ai_message)
```

chain 데코레이터로 인해 upper함수가 RunnableLambda로 변환되었다.

# RunnableLambda 자동 변환

지금까지는 명시적으로 RunnableLambda를 생성하여 Runnable과 연결하는 예를 살펴보았다. 실제로는 명시적을 RunnableLambda를 생성하지 않아도 Runnable과 임의의 함수를 `|`로 연결할 수 있다.

```python
def upper(text: str) -> str:
    return text.upper()

chain = prompt | model | output_parser | upper
```

이때 upper는 자동으로 RunnableLambda로 변환된다.

`|`의 좌우 중 하나가 Runnable인 경우 다른 하나가 함수라면 자동을 RunnableLambda로 변환되도록 설계돼 있다.

LangChain의 공식 문서나 쿡북에서도 RunnableLambda로의 자동 변환이 자주 사용된다.

# Runnable의 입력 타입과 출력 타입에 주의

아무 Runnable끼리라도 연결하기만 하면 잘 작동하는 것은 아니다. 다음 코드는 오류가 발생한다.

```python
def upper(text: str) -> str:
    return text.upper()

chain = prompt | model | upper

output = chain.invoke({"input": "Hello!"})
```

```
AttributeError: 'AIMessage' object has no attribute 'upper'
```

이 오류가 발생한다. 이 오류는 upper함수 내의 `text.upper()` 부분에서 발생한다. model이 AIMessage를 출력하는데 반해, 사용자 정의 upper 함수는 입력을 str을 기대하기 때문이다.

앞서 말했듯이, **Runnable 을 `|`로 연결할 때는 출력 타입과 입력 타입의 일관성에 주의해야 한다.** 

```python
chain = prompt | model | StrOutputParser() | upper
```

이렇게 StrOutputParser를 사용해 model의 출력을 str로 변환한 후 upper 함수에 전달하면 해결된다.

# 사용자 함수를 stream에 대응시키는 방법

위의 chain을 stream 메서드로 호출하면 chain의 실행 결과는 점진적으로 출력되지 않고 처리가 완전히 끝난 시점에 한꺼번에 출력된다. 그 이유는 upper 함수가 입력을 한꺼번에 처리해 한 번에 값을 반환하기 때문이다.

Python에서는 제너레이터 함수를 통해 입력을 점진적으로 처리하여 단계별로 값을 반환하는 함수를 구현할 수 있따. LCEL은 이러한 제너레이터 함수의 연결을 지원하며, 연결된 Chain 전체를 스트리밍 작동에 대응시킬 수 있다.

```python
from typing import Iterator

# 제너레이터 함수 사용
def upper(input_stream: Iterator[str]) -> Iterator[str]:
    for text in input_stream:
        yield text.upper()

chain = prompt | model | StrOutputParser() | upper
for chunk in chain.stream({"input": "Hello!"}):
    print(chunk, end="", flush=True)
```

