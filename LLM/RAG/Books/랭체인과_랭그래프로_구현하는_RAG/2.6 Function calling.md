
# Function calling 개요
Function calling: 2023년 6월에 Chat Completions API에 추가된 기능, 사용 가능한 함수를 LLM에 알려주고 LLM에게 함수를 사용하고 싶다는 판단을 하게 하는 기능(LLM이 함수를 실행하는 것이 아니라 LLM은 함수를 사용하고 싶다는 응답만 반환)

LLM을 애플리케이션에 통합해 활용할 때는 LLM에게 JSON 형식으로 출력하게 하고, 그 내용을 바탕으로 프로그램 내의 함수를 실행하는 처리를 구현하고 싶은 경우가 만핟. 그런 경우 LLM이 잘 응답하도록 API를 구현하고 모델을 파인 튜닝한 것이 Function calling

# Function calling 샘플 코드

`get_current_weather` 이라는 지역을 지정해 날씨를 얻을 수 있는 함수

```python
import json

def get_current_weather(location, unit='fahrenheit'):
	if 'seoul' in location.lower():
		return json.dumps({'location': 'Seoul', 'temperature': '10', 'unit': unit})
	elif 'san francisco' in location.lower():
		return json.dumps(
			{'location': 'San Francisco', 'temperature': '72', 'unit': unit}
		)
	elif 'paris' in location.lower():
		return json.dumps({'location': 'Paris', 'temperature': '22', 'unit': unit})
	else:
		return json.dumps({'location': location, 'temperature': 'unk})
```

LLM이 사용할 수 있는 함수 목록을 정의한다.

```python
tools = [
	{
		'type': 'function',
		'function': {
			'name': 'get_current_weather',
			'description': 'Get the current seather in a given location',
			'parameters': {
				'type': 'object',
				'properties': {
					'location': {
						'type': 'string',
						'description': 'The city and state, e.g. San Francisco, CA'
					},
					'unit': {'type': 'string', 'enum': ['celsius', 'fahrenheit']},
				},
				'required': ['location'],
			},
		},
	}
]
```

다음으로 질문과 함께 API를 호출하고 이때 사용 가능한 함수 목록을 tools라는 인수로 전달한다.

```python
from openai import OpenAI

client = OpenAI()

messages = [
	{'role': 'user', 'content': '서울 날씨는 어떤가요?'},
]

response = client.chat.completions.create(
	model='gpt-4o',
	messages=messages,
	tools=tools,
)
print(response.to_json(indent=2))
```

이 요청에 대해 다음과 같은 응답을 얻을 수 있다.

```json
{
	'id': 'chatcmpl-9jdks3dks',
	'choices': [
		{
			'finish_reason': 'too_calls',
			'index': 0,
			'logprobs': null,
			'message': {
				'content': null,  // 지금까지 실행 예에서 LLM이 생성한 텍스트는 여기에 포함
				'role': 'assistant',
				'tool_calls': [
					{
						'id': 'call_if3ni8dkcjs',
						'function': {  // 'get_current_weather'를 이런 인자로 실행하고 싶다고 쓰여 있음
							'arguments': '{\'location\':\'Seoul\'}',
							'name': 'get_current_weather'
						},
						'type': 'function'
					}
				]
			}
		}
	],
	'created': 12831,
	'model': 'gpt-4o-2024-05-13',
	'object': 'chat.completion',
	'system_fingerprint': 'fp_29313f',
	'usage': {
		'completion_tokens': 15,
		'prompt_tokens': 81,
		'total_tokens': 96
	}
}
```

제공된 함수 목록과 입력 텍스트에서 LLM이 '이 질문에 답하기 위해서는 `get_current_weather` 를 `{'location': 'Seoul'}` 인수로 실행해야 한다'고 판단했다는 것 이다.

이 응답을 얻었음을 대화 기록으로 messages에 추가해 둔다.

```python
response_message = response.choices[0].message
messages.append(response_message.to_dict())
```

LLM이 사용하고 싶어 하는 `get_current_weather` 함수는 우리가 실행해 줘야 한다. LLM이 지정한 인수를 해석해 해당 함수를 호출

```python
available_functions = {
	'get_current_weather': get_current_weather,
}

# 사용하고 싶은 함수는 여러 개 일 수 있으므로 반복문 사용
for tool_call in response_message.tool_calls:
	# 함수를 실행
	function_name = tool_call.function.name
	function_to_call = available_functions[function_name]
	function_args = json.loads(tool_call.function.arguments)
	function_response = function_to_call(
		location=function_args.get("location"),
		unit=function_args.get("unit"),
	)
	print(function_response)
	
	# 함수 실행 결과를 대화 이력으로 messages에 추가
	messages.append(
		{
			"tool_call_id": tool_call.id,
			"role": "tool",
			"name": function_name,
			"content": function_response,
		}
	)

# {"location": "Seoul", "temperature": "10", "unit": null}
```

위 코드에서 함수의 실행결과를 `"role": "tool"`로 하여 대화 기록을 유지하는 messages에 추가했다 이 시점에 출력하면 다음과 같다.
```python
print(json.dumps(messages, ensure_ascii=False, indent=2))
```

```json
[
	{
		"role": "user",
		"content": "서울 날씨는 어떤가요?"
	},
	{
		"content": null,
		"role": "assistant",
		"tool_calls": [
			{
				"id": "call_if3nidhwWs3",
				"function": {
					"arguments": "{\"location\":\"Seoul\"}",
					"name": "get_current_weather"
				},
				"type": "function"
			}
		]
	},
	{
		"tool_call_id": "call_if3ni88asdHDs7",
		"role": "tool",
		"name": "get_current_weather",
		"content": "{\"location\": \"Seoul\", \"temperature\": \"10\", \"unit\": null}"
	}
]
```

이 messages를 사용해 다시 한번 Chat Completions API에 요청을 보낸다.

```python
second_response = client.chat.completions.create(
	model="gpt-4o",
	messages=messages,
)
print(second_response.to_json(indent=2))
```

그러면 최종 답변을 앞서 실행한 실행한 함수의 결과도 고려하여 서울의 날씨를 답변해준다.

```json
{
	"id": "chatcmpl-8jsidJFkdsD",
	"choices": [
		{
			"finish_reason": "stop",
			"index": 0,
			"logprobs": null,
			"message": {
				"content": "서울의 현재 기온은 10도입니다. 자세한 정보를 일고 싶으시면 날씨 예보 사이트를 참조해주세요",
				"role": "assistant"
			}
		}
	],
	"created": 128231,
	"model": "gpt-4o-2024-05-13",
	"object": "chat.completion",
	"system_fingerprint": "fp_dd83jd",
	"usage": {
		"completion_tokens": 43,
		"prompt_tokens": 64,
		"total_tokens": 107
	}
}
```